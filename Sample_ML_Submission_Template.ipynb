{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishka9389/kanishka/blob/main/Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type** - Linear Regression\n",
        "##### **Individual** **project**\n",
        "##### **Name** - **Kanishka**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Car Price Prediction**-\n",
        "                       This project focuses on building a predictive model to estimate car prices based on a wide array of features provided in a structured dataset. The dataset includes 205 observations with 26 features each, encapsulating both numerical and categorical variables related to vehicle specifications and attributes. The primary goal of the project is to apply data preprocessing and machine learning techniques to accurately predict the price of a car, which can have significant applications in the automotive sales, insurance, and valuation sectors.\n",
        "\n",
        "Dataset Overview\n",
        "\n",
        "The dataset comprises several key types of information:\n",
        "\n",
        "Identification and Categorical Descriptors: car_ID, CarName, fueltype, aspiration, doornumber, carbody, drivewheel, enginelocation, enginetype, cylindernumber, and fuelsystem.\n",
        "\n",
        "Dimensional Features: wheelbase, carlength, carwidth, and carheight.\n",
        "\n",
        "Performance and Mechanical Features: curbweight, enginesize, boreratio, stroke, compressionratio, horsepower, peakrpm, citympg, and highwaympg.\n",
        "\n",
        "Target Variable: price.\n",
        "\n",
        "The price variable, which is continuous in nature, serves as the output for the regression models to predict.\n",
        "\n",
        "Exploratory Data Analysis and Preprocessing\n",
        "\n",
        "An initial exploratory data analysis (EDA) would reveal insights into data distribution, correlations, and potential outliers. For example, features like enginesize, horsepower, and curbweight are typically strongly correlated with price, while categorical features such as fueltype or carbody may also influence consumer perception and pricing strategies.\n",
        "\n",
        "Preprocessing steps would involve:\n",
        "\n",
        "Handling Categorical Variables: Encoding non-numeric features using techniques like one-hot encoding.\n",
        "\n",
        "Feature Engineering: Extracting meaningful components from CarName (e.g., brand), removing irrelevant or redundant identifiers like car_ID.\n",
        "\n",
        "Normalization: Scaling features such as enginesize and horsepower to ensure comparability across different ranges.\n",
        "\n",
        "Dealing with Inconsistencies: Standardizing text fields (e.g., misspellings in car brand names).\n",
        "\n",
        "Modeling Approach\n",
        "\n",
        "Given the regression nature of the task, multiple machine learning algorithms could be explored and compared, such as:\n",
        "\n",
        "Linear Regression: For baseline performance and interpretability.\n",
        "\n",
        "Ridge and Lasso Regression: To handle multicollinearity and perform feature selection.\n",
        "\n",
        "Decision Tree and Random Forest Regressors: To capture non-linear relationships.\n",
        "\n",
        "Gradient Boosting Methods (XGBoost/LightGBM): For improved accuracy with ensemble learning.\n",
        "\n",
        "Support Vector Regression (SVR) and Neural Networks: For complex modeling needs, if necessary.\n",
        "\n",
        "Models would be evaluated using appropriate regression metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R² score."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kanishka9389/kanishka.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**-\n",
        "\n",
        "In the competitive automotive market, accurately determining the price of a vehicle is critical for manufacturers, dealers, and consumers. Car prices are influenced by a variety of factors, including technical specifications, design features, brand reputation, and performance metrics. However, manual estimation or reliance on limited criteria can lead to inconsistent and inaccurate pricing, potentially impacting sales, customer satisfaction, and market competitiveness.\n",
        "\n",
        "The objective of this project is to develop a machine learning model that can accurately predict the price of a car based on its features. Using a structured dataset containing 205 entries and 26 variables—including engine characteristics, fuel type, body style, and performance parameters—this model aims to identify the most influential features and generate price predictions that align closely with actual market values.\n",
        "\n",
        "By automating the pricing process through data-driven insights, this solution will assist stakeholders in making informed decisions related to car valuation, purchasing, and sales strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/CarPrice_project.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "10Rko0KGT47M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "89yCR-pGV24Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "I6BiQOGUje6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "GKaeLkIijn_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "lKF-HrSojvX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['curbweight'], inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 **Car Price Prediction**: the dataset is likely related to predicting car prices,as indicated by the file name (CarOrice_project.csv)and the presence of a 'price'column.\n",
        "2 **Various Car Features**:The dataset contains information about various car features like car make and model,fuel type,engine specifications,dimensions,mileageand more.Numerical and Categorical Data: The dataset includes both numerical (e.g., horsepower, mileage) and categorical (e.g., fuel type, car body type) variables.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and 'carbody' is the relevant column\n",
        "Top3_carbody = df['carbody'].value_counts().head(3).reset_index()\n",
        "Top3_carbody.columns = ['CarBody', 'Count']\n",
        "print(Top3_carbody)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identification:**\n",
        "\n",
        "car_ID: Unique car identifier.\n",
        "CarName: Car model.\n",
        "**Categorical:** Describing car attributes like fuel type, engine, body style, etc.\n",
        "\n",
        "fueltype, aspiration, doornumber, carbody, drivewheel, enginelocation, enginetype, cylindernumber, fuelsystem\n",
        "**Numerical:** Measurable car characteristics like size, weight, engine specs, mileage, etc.\n",
        "\n",
        "symboling, wheelbase, carlength, carwidth, carheight, curbweight, enginesize, boreratio, stroke, compressionratio, horsepower, peakrpm, citympg, highwaympg\n",
        "**Target:** The variable to predict.\n",
        "\n",
        "price: Car price."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Unique Values: {unique_values}\\n\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Removing irrelevant columns:\n",
        "# Check if columns exist before dropping\n",
        "if 'CarName' in df.columns and 'car_ID' in df.columns:\n",
        "    df = df.drop(['CarName', 'car_ID'], axis=1)\n",
        "else:\n",
        "    print(\"Columns 'CarName' and/or 'car_ID' have already been removed.\")\n",
        "\n",
        "# 2. Renaming columns for better readability:\n",
        "df = df.rename(columns={'wheelbase': 'wheel_base', 'enginesize': 'engine_size'})\n",
        "\n",
        "# 3. Handling missing values:\n",
        "# Assuming no missing values based on the provided dataset\n",
        "# If there were missing values, you could use:\n",
        "# df['horsepower'].fillna(df['horsepower'].mean(), inplace=True)\n",
        "\n",
        "# 4. Feature engineering:\n",
        "# Creating a new feature 'power_to_weight' (example)\n",
        "# df['power_to_weight'] = df['horsepower'] / df['curbweight']\n",
        "\n",
        "# 5. Data type conversion:\n",
        "# Converting 'symboling' to categorical (if needed)\n",
        "# df['symboling']"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulations:\n",
        "\n",
        "Removed irrelevant columns (CarName, car_ID).\n",
        "\n",
        "Renamed columns for better readability (wheelbase to wheel_base, enginesize to engine_size).\n",
        "\n",
        "Included handling for potential missing values (though none were present).\n",
        "\n",
        "Provided an example of feature engineering (power_to_weight, but commented out).\n",
        "\n",
        "Included an example of data type conversion\n",
        "(symboling to categorical, but commented out).\n",
        "\n",
        "Insights:\n",
        "\n",
        "Simplified the dataset, reducing noise and potential dimensionality issues.\n",
        "\n",
        "Improved code readability and consistency.\n",
        "\n",
        "Prepared the data for analysis and modeling by addressing missing values, potentially engineering features, and potentially handling categorical variables appropriately."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.histplot(df['price'], bins=20, kde=True)  # Use histplot for histogram with optional KDE\n",
        "plt.title('Distribution of Car Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the histogram (specifically using sns.histplot) for this visualization because:\n",
        "\n",
        "**Distribution:** Histograms are ideal for visualizing the distribution of a single numerical variable, like car prices.\n",
        "**Frequency:** They show the frequency of data points within specific price ranges, highlighting common price points.\n",
        "**Patterns:** They can reveal skewness, central tendency, and outliers in the data.\n",
        "Continuous Data: Histograms are designed for continuous numerical data like car prices.\n",
        "**Easy Interpretation:** They are easy to understand, with price ranges on the x-axis and frequency on the y-axis.\n",
        "**KDE:** The kde=True option adds a smooth curve to highlight the distribution's shape."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution:** Shows the overall shape (likely right-skewed), indicating more lower-priced cars and fewer high-priced ones.\n",
        "**Central Tendency:** Gives an idea of the typical price range (mode) and approximate mean/median.\n",
        "**Price Range:** Reveals the minimum and maximum prices in the dataset.\n",
        "**Outliers:** Helps identify unusual prices outside the typical range.\n",
        "**Frequency:** Shows the number of cars within different price ranges, indicating common price points."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Pricing, Inventory, Marketing, Competitive Analysis, Product Development.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "**Ignoring demand:** Not aligning with customer preferences for price ranges.\n",
        "\n",
        "**Inventory mismanagement: **Overstocking or understocking based on inaccurate price distribution assumptions.\n",
        "\n",
        "**Misaligned marketing:** Targeting wrong customer segments with ineffective pricing messages.\n",
        "\n",
        "**Lack of innovation**: Missing opportunities to address market gaps or changing customer price preferences.\n",
        "\n",
        "Justification: The histogram provides valuable data about the market, and using it strategically can drive positive outcomes. However, misinterpreting or ignoring its insights can have negative consequences for business growth."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.scatterplot(x='horsepower', y='price', data=df)  # Create scatter plot\n",
        "plt.title('Horsepower vs. Price')\n",
        "plt.xlabel('Horsepower')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the scatter plot (specifically using sns.scatterplot) for this visualization because:\n",
        "\n",
        "**Visualizing Relationships:** Scatter plots are ideal for showing the relationship between two numerical variables, like horsepower and price.\n",
        "\n",
        "**Identifying Patterns:** They help see if there's a correlation (positive, negative, or none) between the variables.\n",
        "\n",
        "**Detecting Outliers:** Scatter plots make it easy to spot unusual data points.\n",
        "\n",
        "**Suitable for Continuous Data:** Both horsepower and price are continuous numerical data, making scatter plots appropriate.\n",
        "\n",
        "**Intuitive Interpretation: **They are relatively easy to understand and interpret.\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation:** Shows whether there's a relationship between horsepower and price (likely positive).\n",
        "\n",
        "**Strength of Relationship:** Indicates how strong the correlation is (e.g., strong, moderate, weak).\n",
        "\n",
        "**Outliers:** Reveals any unusual cars with unexpected horsepower-price combinations.\n",
        "\n",
        "**Price Trends:** Helps see how price changes as horsepower increases.\n",
        "\n",
        "**Potential Clusters:** Might identify groups of cars with similar horsepower and price ranges."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing Strategy**: The scatter plot can help businesses understand the relationship between horsepower and price, which is crucial for setting competitive prices.\n",
        "\n",
        "**Product Development:** The insights can guide product development decisions.\n",
        "\n",
        "**Marketing and Sales**: The insights can guide marketing and sales strategies.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "\n",
        "**Misalignment with demand:** Offering horsepower levels that don't match customer preferences.\n",
        "\n",
        "Overemphasis on horsepower: Focusing solely on horsepower when other factors might be more important to customers (e.g., fuel efficiency, features).\n",
        "\n",
        "Neglecting price sensitivity: Ignoring the potential impact of price differences on customer choices, particularly in certain horsepower segments.\n",
        "\n",
        "Justification:\n",
        "\n",
        "Misalignment with market: Businesses risk losing customers if their offerings don't meet customer preferences revealed in the scatter plot.\n",
        "Inefficient resource allocation: Overemphasizing horsepower might divert resources from other important aspects of product development or marketing.\n",
        "Lost sales opportunities: Neglecting price sensitivity could lead to pricing products out of the market for certain customer segments."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'carbody' is the column for car body types\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.countplot(x='carbody', data=df)  # Create bar chart\n",
        "plt.title('Distribution of Car Body Types')\n",
        "plt.xlabel('Car Body Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the bar chart (specifically using sns.countplot) for this visualization because:\n",
        "\n",
        "Suitable for Categorical Data: Bar charts are the primary choice for visualizing the distribution of categorical data. Car body types are categorical variables, meaning they represent distinct categories or groups (e.g., sedan, hatchback, SUV). Bar charts effectively show the frequency or count of each category.\n",
        "\n",
        "sns.countplot for Frequency: The sns.countplot function in Seaborn is specifically designed for creating bar charts that display the counts of different categories in a column. It simplifies the process of generating a frequency distribution for categorical data.\n",
        "\n",
        "Clear Comparison of Categories: Bar charts make it easy to compare the frequencies of different car body types. The height of each bar directly corresponds to the count of cars belonging to that category, allowing for quick visual comparisons.\n",
        "\n",
        "Easy Interpretation: Bar charts are generally easy to understand and interpret. The x-axis represents the different car body types, and the y-axis represents the count or frequency of each category. This simple structure makes it accessible to a wide audience.\n",
        "\n",
        "Effective for Showing Popularity: In this specific case, we want to understand the popularity or distribution of different car body types. Bar charts are an effective way to visually represent this information, highlighting the most and least frequent categories."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Popular Car Body Types: The chart will clearly show which car body types are most frequent in the dataset. These will be the categories with the tallest bars. For example, if the 'sedan' category has the tallest bar, it indicates that sedans are the most common car body type in the dataset.\n",
        "\n",
        "Least Popular Car Body Types: Similarly, the chart will reveal the least frequent car body types, represented by the shortest bars. For example, if the 'convertible' category has a very short bar, it suggests that convertibles are relatively uncommon in the dataset.\n",
        "\n",
        "Overall Distribution: You can get a sense of the overall distribution of car body types. Is it relatively balanced, with similar frequencies across categories, or are there a few dominant categories and several less common ones?\n",
        "\n",
        "Market Trends: The distribution of car body types can provide insights into market trends and customer preferences. For example, if SUVs have a high frequency in the dataset, it might indicate a growing popularity of SUVs in the market.\n",
        "\n",
        "Inventory Management: For businesses, this information can be valuable for inventory management decisions. They might want to stock more cars of the popular body types to meet customer demand and avoid overstocking less popular ones."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Targeted Marketing: Businesses can use the insights to tailor their marketing campaigns to specific customer segments. For example, if the bar chart shows that sedans are the most popular car body type, businesses can focus their marketing efforts on promoting sedans to a wider audience.\n",
        "Negative Growth Insights:\n",
        "\n",
        "Ignoring Customer Preferences: If businesses ignore the insights from the bar chart and fail to offer a sufficient variety of popular car body types, they risk losing customers to competitors who do. This can lead to negative growth in sales and market share.\n",
        "Overstocking Unpopular Models: If businesses overstock unpopular car body types, they incur unnecessary inventory costs and risk having unsold inventory. This can negatively impact profitability and cash flow.\n",
        "Misaligned Marketing Efforts: If businesses target their marketing efforts on unpopular car body types, they waste resources and fail to reach their target audience effectively. This can lead to a decline in sales and brand awareness.\n",
        "Lack of Innovation: If businesses fail to adapt to changing customer preferences and market trends, they risk losing their competitive edge. This can result in negative growth and a decline in market share.\n",
        "Justification:\n",
        "\n",
        "The bar chart provides valuable insights into the popularity of different car body types, which is a key factor in understanding customer preferences and market trends. Businesses can leverage these insights to make data-driven decisions about marketing, product development, inventory management, and pricing strategies. By aligning their offerings with customer preferences and market trends, businesses can enhance their chances of success and drive positive business impact. However, failing to consider the insights from the bar chart can lead to negative growth due to factors like ignoring customer preferences, overstocking unpopular models, misaligned marketing efforts, and a lack of innovation."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.scatterplot(x='engine_size', y='price', data=df)  # Use the correct column name 'engine_size'\n",
        "plt.title('Engine Size vs. Price')\n",
        "plt.xlabel('Engine Size')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the scatter plot (specifically using sns.scatterplot) for this visualization because:\n",
        "\n",
        "**Scatter plots are ideal for showing the relationship between two numerical **variables, like engine size and price. They help reveal **patterns, correlations, and outliers**, making them suitable for exploring how engine size might influence car prices.\n"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Correlation:** Engine size and price tend to increase together.\n",
        "\n",
        "**Correlation Strength:** How closely points cluster indicates the strength of this relationship.\n",
        "\n",
        "**Outliers:** Unusual cars with unexpected engine size/price combinations.\n",
        "\n",
        "**Price Ranges:** Shows how price varies for different engine sizes.\n",
        "\n",
        "**Price Segmentation:** Potential for grouping cars based on engine size and price.\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Product Development:** Guide decisions by identifying engine size/price point demand.\n",
        "\n",
        "**Pricing Strategy:** Understand price elasticity within engine size segments.\n",
        "\n",
        "**Competitive Analysis:** Benchmark engine size/price offerings against competitors.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "**Misalignment with Customer Preferences:** Offering wrong engine sizes or price points.\n",
        "\n",
        "**Overemphasis on Engine Size:** Ignoring other customer needs (fuel efficiency, features).\n",
        "\n",
        "**Neglecting Price Sensitivity:** Misjudging customer willingness to pay for larger engines.\n",
        "\n",
        "**Justification:** Aligning product offerings, pricing, and marketing with customer preferences (revealed in the scatter plot) drives growth. Ignoring these insights can lead to lost sales, overstocked inventory, and missed opportunities."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_cars = df.head(10)  # Assuming 'df' is your original DataFrame\n",
        "\n",
        "# Assuming 'carbody' is a relevant column for your x-axis\n",
        "# If you intended to use a different column, replace 'carbody' accordingly\n",
        "plt.figure(figsize=(10, 5))\n",
        "# Access one of the one-hot encoded columns for carbody, for instance 'carbody_hardtop'\n",
        "plt.plot(top_10_cars['carbody_hardtop'], top_10_cars[\"citympg\"], marker='o', linestyle='-', color='b')\n",
        "\n",
        "plt.xlabel(\"Car Body Type\", fontsize=12)  # Update x-axis label\n",
        "plt.ylabel(\"City Mileage (MPG)\", fontsize=12)\n",
        "plt.title(\"Top 10 Cars vs City Mileage\", fontsize=15)\n",
        "\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the line chart (specifically using plt.plot) for this visualization because:\n",
        "\n",
        "**Line charts are effective for showing trends and comparisons over a discrete variable.** In this case, the discrete variable is the top 10 cars, and the line chart helps visualize how mileage changes across these cars and to highlight the differences and top performers. They are a concise way to present specific mileage values of fuel-efficient vehicles for potential fuel savings."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mileage Variation:** Shows how city mileage (MPG) varies across the top 10 cars.\n",
        "\n",
        "**Top Performers:** Highlights cars with the highest mileage for fuel efficiency.\n",
        "\n",
        "**Relative Comparisons:** Easy to compare mileage between different cars.\n",
        "\n",
        "**Trends:** May reveal trends in mileage based on car ranking (e.g., price, rating).\n",
        "\n",
        "**Outliers:** Identifies cars with unusual mileage compared to others.\n",
        "\n",
        "**Fuel Savings:** Provides insights for potential fuel savings based on mileage."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Marketing and Sales:** Businesses can promote fuel-efficient models and target advertising based on the insights.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "**Ignoring Customer Preferences:** Lack of fuel-efficient options could lead to lost customers.\n",
        "\n",
        "**Overlooking Emerging Trends:** Not adapting to changing fuel economy standards could make models less competitive.\n",
        "\n",
        "**Misaligned Marketing Efforts**: Promoting cars with lower city mileage while customer preferences shift towards fuel-efficient vehicles might be ineffective.\n",
        "\n",
        "Missed Product Development Opportunities: Not investing in fuel-efficient technologies could result in falling behind competitors.\n",
        "\n",
        "Justification:\n",
        "\n",
        "The line chart provides valuable insights into fuel efficiency, which influences customer decisions. Leveraging these insights for marketing and product development can drive positive business impact. Ignoring them could lead to negative growth due to misalignment with market trends and customer preferences."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # Import pandas\n",
        "\n",
        "# Assuming 'df' is your original DataFrame\n",
        "# Recalculate Top3_carbody here\n",
        "Top3_carbody = df['carbody'].value_counts().head(3).reset_index()\n",
        "Top3_carbody.columns = ['CarBody', 'Count']\n",
        "\n",
        "plt.figure(figsize=(8, 10))\n",
        "plt.pie(Top3_carbody['Count'], labels=Top3_carbody['CarBody'], autopct='%.0f%%', explode=[0.02] * 3)\n",
        "plt.title('Top 3 Car Body Categories Distribution', fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the pie chart (specifically using plt.pie) for this visualization because:\n",
        "\n",
        "**Pie charts effectively visualize the proportions or parts of a whole, allowing for easy comparison of the relative sizes of the top 3 car body categories.** They provide a clear and simple representation, emphasizing the relative importance of each category. This makes them well-suited for highlighting the distribution and popularity of different car body types within the top 3."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart reveals the distribution of the top 3 car body categories, highlighting the** dominant car body type**, their **relative** **proportions**, potential **market share,** and possible **customer preferences.** This information can be valuable for businesses in understanding market trends and making informed decisions.\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:** Yes, the insights can help with pricing strategies, targeted marketing, and inventory optimization.\n",
        "\n",
        "**Negative Growth Insights:** Ignoring customer preferences for certain car body types could lead to lost sales and misaligned inventory. Overstocking unpopular models could also negatively impact profitability.\n",
        "\n",
        "**Justification:** Aligning business strategies with customer preferences, revealed in the pie chart, can drive positive impact. Neglecting these preferences can lead to negative growth due to misalignment with market demand."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid()\n",
        "# Replace 'car_review_df' with the actual DataFrame name ('df' in your case)\n",
        "size_distribution_graph = sns.kdeplot(df['price'], color=\"lightgreen\", shade = True)\n",
        "plt.title('Average price',size = 20);"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the KDE plot (specifically using sns.kdeplot) for this visualization because:\n",
        "\n",
        "KDE plots are excellent for visualizing the probability density of continuous data like 'price', providing a smooth, continuous representation of the distribution and revealing patterns such as skewness, central tendency, and potential outliers. This makes them well-suited for understanding the overall shape and spread of the price distribution, which is crucial for this analysis."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the KDE Plot of Car Prices:\n",
        "\n",
        "**Price Distribution:** Shows how car prices are spread.\n",
        "\n",
        "**Typical Price:** Indicates the most frequent price range.\n",
        "\n",
        "**Outliers:** Reveals any unusually high or low prices.\n",
        "\n",
        "**Price Segmentation:** May suggest different price groups in the market."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:** Yes, the insights can guide pricing strategies, inventory management, marketing, and product development.\n",
        "\n",
        "**Negative Growth Insights:** Ignoring customer preferences (price sensitivity), overemphasizing the average price, misinterpreting outliers, or lacking innovation could lead to negative growth.\n",
        "\n",
        "**Justification:** Aligning business strategies with the insights (customer preferences, market trends) from the KDE plot leads to positive impact, while ignoring them can cause misalignment and hinder growth."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = df.select_dtypes(include=np.number)\n",
        "correlation_matrix = numerical_features.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the heatmap (specifically using sns.heatmap) for this visualization because:\n",
        "\n",
        "Heatmaps are excellent for visualizing correlation matrices, which show the relationships between multiple numerical variables. The heatmap uses color intensity to represent the strength and direction of correlations, making it easy to identify patterns and relationships at a glance. This makes it ideal for quickly understanding the complex relationships within the dataset."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Strength:** Shows how strongly numerical features are related (positive/negative).\n",
        "\n",
        "**Key Relationships:** Highlights the most important relationships between variables.\n",
        "\n",
        "**Multicollinearity:** Identifies features with strong correlations (redundancy).\n",
        "\n",
        "**Feature Selection:** Helps choose relevant features for machine learning.\n",
        "\n",
        "**Data Understanding:** Provides a comprehensive view of numerical relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:** The insights can be leveraged for pricing strategies, product development, targeted marketing, inventory management and competitive analysis.\n",
        "\n",
        "**Insights that Lead to Negative Growth:** Ignoring negative correlations, overemphasizing highly correlated features, misinterpreting weak correlations, or ignoring multicollinearity.\n",
        "\n",
        "**Justification:** By understanding feature relationships, businesses can make data-driven decisions for positive impact. Neglecting or misinterpreting these relationships can hinder growth due to misaligned strategies."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.scatterplot(x='citympg', y='price', data=df)\n",
        "plt.title('City MPG vs. Price')\n",
        "plt.xlabel('City MPG')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the scatter plot (specifically using sns.scatterplot) for this visualization because:\n",
        "\n",
        "Scatter plots are ideal for showing the relationship between two numerical variables, like citympg and price. They help reveal patterns, correlations, and outliers, making them suitable for exploring how city mileage might influence car prices."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative Correlation:** City MPG and price tend to have an inverse relationship (higher MPG, lower price).\n",
        "\n",
        "**Correlation Strength:** How closely points cluster indicates the strength of this relationship.\n",
        "\n",
        "**Outliers:** Unusual cars with unexpected MPG/price combinations.\n",
        "\n",
        "**Price Ranges:** Shows how price varies for different MPG levels.\n",
        "\n",
        "**Price Segmentation:** Potential for grouping cars based on MPG and price.\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:** Yes, the insights can guide pricing strategies, inventory management, marketing, and product development.\n",
        "\n",
        "**Negative Growth Insights:** Ignoring customer preferences (price sensitivity), overemphasizing the average price, misinterpreting outliers, or lacking innovation could lead to negative growth.\n",
        "\n",
        "**Justification:** Aligning business strategies with the insights (customer preferences, market trends) from the scatter plot leads to positive impact, while ignoring them can cause misalignment and hinder growth.\n",
        "\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.histplot(df['price'], bins=20, kde=True)  # Use histplot for histogram with optional KDE\n",
        "plt.title('Distribution of Car Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.histplot(df['price'], bins=20, kde=True)  # Use histplot for histogram with optional KDE\n",
        "plt.title('Distribution of Car Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the histogram (specifically using sns.histplot) for this visualization because:\n",
        "\n",
        "**Histograms are excellent for visualizing the distribution of continuous numerical data like 'price', showing the frequency of data points within specific price ranges, and revealing patterns such as skewness, central tendency, and outliers.** This makes them well-suited for understanding the overall shape and spread of the price distribution, which is crucial for this analysis."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Central Tendency:** Shows the typical or average price range.\n",
        "\n",
        "**Spread:** Indicates the range and variability of prices.\n",
        "\n",
        "**Skewness:** Reveals if the distribution is symmetrical or skewed.\n",
        "\n",
        "**Outliers:** Identifies unusual or extreme prices.\n",
        "\n",
        "**Price Segmentation:** May suggest different price groups in the market.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing Strategy:** Understand typical price ranges and customer price sensitivity.\n",
        "\n",
        "**Inventory Management:** Optimize stock levels based on popular price ranges.\n",
        "\n",
        "**Marketing & Sales:** Target specific price segments for effective marketing.\n",
        "\n",
        "**Product Development:** Identify gaps and opportunities for new car models.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "**Ignoring Customer Preferences:** Neglecting price sensitivity can lead to lost sales.\n",
        "\n",
        "**Overemphasis on Average:** Focusing solely on average price might overlook other segments.\n",
        "\n",
        "**Misinterpreting Outliers:** Dismissing unusual prices could miss potential opportunities.\n",
        "\n",
        "Lack of Innovation: Failing to adapt to changing price trends could hinder growth.\n",
        "\n",
        "Justification:\n",
        "\n",
        "Positive: Aligning strategies with customer preferences and market trends revealed in the histogram drives growth.\n",
        "Negative: Ignoring these insights leads to misalignment with market demands and customer expectations, hindering growth."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "sns.scatterplot(x='horsepower', y='citympg', data=df)\n",
        "plt.title('Horsepower vs. City MPG')\n",
        "plt.xlabel('Horsepower')\n",
        "plt.ylabel('City MPG')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the scatter plot (specifically using sns.scatterplot) for this visualization because:\n",
        "\n",
        "**Scatter plots are ideal for visualizing the relationship between two numerical variables, in this case, horsepower and city mileage (citympg).** They effectively reveal patterns, correlations, and outliers, making them suitable for exploring how these two variables might be related."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relationship:** Shows how horsepower and city mileage are related (likely negative correlation).\n",
        "\n",
        "**Correlation Strength:** Indicates how strong the relationship is (e.g., strong, moderate, weak).\n",
        "\n",
        "**Outliers: **Reveals unusual cars with unexpected horsepower/city mileage combinations.\n",
        "\n",
        "**Trends**: Helps see how city mileage changes as horsepower increases.\n",
        "\n",
        "**Segmentation:** Potential for grouping cars based on horsepower and city mileage."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Product Strategy: Guide decisions on horsepower/fuel efficiency balance.\n",
        "\n",
        "Marketing: Highlight fuel efficiency or performance based on target segments.\n",
        "\n",
        "Pricing: Adjust prices based on horsepower and fuel efficiency combinations.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "Ignoring Preferences: Not offering cars with desired horsepower/fuel efficiency combinations.\n",
        "\n",
        "Misaligned Marketing: Promoting fuel efficiency to performance-focused buyers.\n",
        "Inaccurate Pricing: Overpricing or underpricing based on misinterpreting trends.\n",
        "\n",
        "Justification:\n",
        "\n",
        "Positive: Aligning offerings with customer preferences revealed in the scatter plot drives growth.\n",
        "Negative: Ignoring customer preferences or market trends can lead to lost sales and missed opportunities."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Create bins for car width\n",
        "car_width_bins = pd.cut(df['carwidth'], bins=5, labels=['Very Narrow', 'Narrow', 'Medium', 'Wide', 'Very Wide'])\n",
        "\n",
        "# 2. Calculate average price for each bin\n",
        "avg_price_by_width = df.groupby(car_width_bins)['price'].mean().reset_index()\n",
        "\n",
        "# 3. Create the bar graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(avg_price_by_width['carwidth'], avg_price_by_width['price'])\n",
        "plt.title('Average Price by Car Width')\n",
        "plt.xlabel('Car Width Bins')\n",
        "plt.ylabel('Average Price')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons for Choosing a Bar Graph:**\n",
        "\n",
        "**Bar charts are effective for comparing average values across different categories, in this case, car width bins.** They clearly show how average price changes with car width, making it easy to identify trends and potential price differences."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Insights from the Bar Graph of Average Price by Car Width:**\n",
        "\n",
        "**Price Trend:** Shows how average car price changes with car width (likely positive correlation).\n",
        "\n",
        "**Price Differences:** Reveals average price variations between car width categories.\n",
        "\n",
        "**Market Segmentation:** Potential for grouping cars based on width and price sensitivity.\n",
        "\n",
        "**Pricing Strategy:** Insights for setting competitive prices based on car width."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Pricing Strategy: Optimize pricing based on car width and customer preferences.\n",
        "\n",
        "Product Development: Understand demand for different car widths and price points.\n",
        "\n",
        "Marketing: Target specific segments with messages about width and value.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "Ignoring Preferences: Not offering car widths or price points that align with demand.\n",
        "\n",
        "Misaligned Marketing: Promoting wide cars to price-sensitive buyers or vice versa.\n",
        "\n",
        "Inaccurate Pricing: Overpricing or underpricing based on misinterpreting trends.\n",
        "\n",
        "Justification:\n",
        "\n",
        "Positive: Aligning offerings with customer preferences revealed in the bar chart drives growth.\n",
        "\n",
        "Negative: Ignoring these preferences or market trends can lead to lost sales and missed opportunities."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "# and 'CarName' originally contained year information\n",
        "\n",
        "# Reload the original DataFrame to get the 'CarName' column back\n",
        "df = pd.read_csv('/content/CarPrice_project.csv')\n",
        "\n",
        "# 1. Extract year from 'CarName' (example: \"toyota corona mark ii 1992\")\n",
        "df['year'] = df['CarName'].str.extract(r'(\\d{4})').astype(float)  # Extract and convert to numeric\n",
        "\n",
        "# 2. Calculate average price for each year\n",
        "avg_price_by_year = df.groupby('year')['price'].mean().reset_index()\n",
        "\n",
        "# 3. Create the line graph\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "plt.plot(avg_price_by_year['year'], avg_price_by_year['price'], marker='o', linestyle='-')\n",
        "plt.title('Average Car Price Over the Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Price')\n",
        "plt.grid(True)  # Add a grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons for Choosing a Line Graph:**\n",
        "\n",
        "**Line charts are effective for showing trends over time.** In this case, it visualizes how average car prices change over the years, allowing for easy identification of patterns and overall price trends."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the insights from the line graph:\n",
        "\n",
        "**Overall Price Trend:** Shows whether average car prices are increasing, decreasing, or stable over time.\n",
        "\n",
        "**Price Fluctuations:** Highlights any significant price changes or periods of volatility.\n",
        "\n",
        "**Year-to-Year Comparisons:** Allows for easy comparison of average prices between different years."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:** Yes, understanding price trends can help with pricing strategies, inventory management, and market forecasting.\n",
        "\n",
        "**Negative Growth Insights:** Ignoring downward trends could lead to overpricing and lost sales. Not adapting to changing market conditions could also hinder growth.\n",
        "\n",
        "**Justification:** Aligning business strategies with market trends (revealed in the chart) drives positive impact. Neglecting these trends can lead to negative growth due to misalignment with market dynamics."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Select numerical features for correlation analysis\n",
        "numerical_features = df.select_dtypes(include=['number'])\n",
        "\n",
        "# 2. Calculate the correlation matrix\n",
        "correlation_matrix = numerical_features.corr()\n",
        "\n",
        "# 3. Create the heatmap\n",
        "plt.figure(figsize=(12, 8))  # Adjust figure size as needed\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the heatmap because it's excellent for visualizing correlation matrices, showing relationships between multiple numerical variables using color intensity to represent correlation strength and direction, making it easy to identify patterns and relationships at a glance."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights from the Correlation Heatmap:**\n",
        "\n",
        "**Correlation Strength:** Shows how strongly numerical features are related (positive/negative).\n",
        "\n",
        "**Key Relationships:** Highlights the most important relationships between variables.\n",
        "\n",
        "**Multicollinearity:** Identifies features with strong correlations (redundancy).\n",
        "\n",
        "**Feature Selection:** Helps choose relevant features for machine learning.\n",
        "\n",
        "**Data Understanding:** Provides a comprehensive view of numerical relationships."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Select numerical features for the pair plot\n",
        "numerical_features = ['horsepower', 'citympg', 'highwaympg', 'price']  # Add more features as needed\n",
        "\n",
        "# 2. Create the pair plot\n",
        "sns.pairplot(df[numerical_features])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the pair plot because it's great for visualizing relationships between multiple numerical features, showing both individual distributions (histograms) and pairwise relationships (scatter plots) in a concise grid, making it easy to identify patterns and correlations."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights from the Pair Plot:**\n",
        "\n",
        "**Individual Distributions:** Shows the distribution (shape, central tendency, spread) of each numerical feature.\n",
        "\n",
        "**Relationships:** Reveals correlations (positive, negative, or none) between pairs of features.\n",
        "\n",
        "**Outliers:** Helps identify unusual data points that deviate from the general patterns.\n",
        "\n",
        "**Data Patterns:** Provides a visual overview of patterns and relationships within the numerical data."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statements:**\n",
        "\n",
        "**1-Cars with higher horsepower** tend to have higher prices. **bold text** (Based on the scatter plot of 'horsepower' vs. 'price', which likely showed a positive correlation.)\n",
        "\n",
        "**Cars with higher city MPG (fuel efficiency) tend to have lower prices.** (Based on the scatter plot of 'citympg' vs. 'price', which likely showed a negative correlation.)\n",
        "\n",
        "**There is a significant difference in price between cars with different car body types (e.g., sedan, hatchback, SUV).** (Based on the count plot of 'carbody', which showed varying frequencies of different car body types, suggesting potential price differences.)"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no significant relationship between a car's horsepower and its price.\n",
        "\n",
        "**Alternate Hypothesis (H1):** There is a significant relationship between a car's horsepower and its price.\n",
        "\n",
        "**In simpler terms:**\n",
        "Null Hypothesis: Horsepower doesn't really affect the price of a car.\n",
        "Alternate Hypothesis: Horsepower does affect the price of a car."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# 1. Select the relevant columns\n",
        "enginesize = df['enginesize']\n",
        "price = df['price']\n",
        "\n",
        "# 2. Perform Pearson correlation test\n",
        "correlation_coefficient, p_value = pearsonr(enginesize, price)\n",
        "\n",
        "# 3. Print the results\n",
        "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pearson correlation test**"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pearson correlation test was chosen because it's the most appropriate for assessing the relationship between two continuous variables (horsepower and price) and determining if the relationship is statistically significant, which is the goal of this analysis. It also aligns with the nature of the data and the research question being explored."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** City MPG has no effect on a car's price.\n",
        "\n",
        "**Alternate Hypothesis (H1):** City MPG does affect a car's price."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pearson correlation test.**"
      ],
      "metadata": {
        "id": "rVdts_yS7gwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "citympg = df['citympg']\n",
        "price = df['price']\n",
        "\n",
        "# Calculate Pearson correlation and p-value\n",
        "correlation, p_value = stats.pearsonr(citympg, price)\n",
        "\n",
        "print(f\"Pearson correlation coefficient: {correlation}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the **Pearson correlation test **because it's the best way to check if two things that can be measured with numbers (like city MPG and price) are related to each other in a straight-line kind of way. It also tells us if that relationship is strong and if it's likely real or just a coincidence.\n",
        "\n",
        "\n",
        "\n",
        "Type of Data: Both 'horsepower' and 'citympg' are continuous numerical variables.\n",
        "\n",
        "Hypothesis: We are testing for a correlation between these two variables, specifically a negative correlation.\n",
        "\n",
        "Assumptions: Similar to Statement 1, the Pearson correlation test's assumptions are generally met in this case.\n",
        "\n",
        "Purpose: The Pearson correlation test is again appropriate for measuring the strength and direction of a linear relationship between two continuous variables."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no significant difference in price between cars with different car body types.\n",
        "\n",
        "**Alternate Hypothesis (H1):** There is a significant difference in price between cars with different car body types."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as sm\n",
        "import statsmodels.stats.anova as smsa # Import the correct module for anova_lm\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "model = sm.ols('price ~ carbody', data=df).fit()\n",
        "anova_table = smsa.anova_lm(model, typ=2) # Use smsa to call anova_lm\n",
        "\n",
        "print(anova_table)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **ANOVA (Analysis of Variance).**"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANOVA **was chosen because it tests for differences in average price across different car body types. In this case, we want to see if car body type influences price, which makes ANOVA the appropriate test."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No missing value imputation techniques were used initially due to an incorrect assumption."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'price' is the column with outliers\n",
        "upper_limit = df['price'].quantile(0.95)  # 95th percentile\n",
        "lower_limit = df['price'].quantile(0.05)  # 5th percentile\n",
        "\n",
        "df['price'] = np.where(df['price'] > upper_limit, upper_limit,\n",
        "                        np.where(df['price'] < lower_limit, lower_limit, df['price']))"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technique: Winsorization**\n",
        "\n",
        "**Why:**\n",
        "\n",
        "1-Keeps all the data, just adjusts the extreme values.\n",
        "\n",
        "2-Makes the data more reliable for analysis by limiting the influence of outliers.\n",
        "\n",
        "3-It's a common and effective way to deal with outliers without losing too much information."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(categorical_columns)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technique:** One-Hot Encoding\n",
        "\n",
        "**Why:**\n",
        "\n",
        "1-Converts categories into numbers that machine learning models can understand.\n",
        "\n",
        "2-Avoids imposing a false order or relationship between categories (like saying \"red\" is greater than \"blue\").\n",
        "\n",
        "3-It's a widely used and effective way to represent categorical data in a way that models can use."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "contractions_dict = {\n",
        "    \"don't\": \"do not\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"they're\": \"they are\",\n",
        "    # ... add more contractions\n",
        "}\n",
        "\n",
        "def expand_contractions(text):\n",
        "    for contraction, expansion in contractions_dict.items():\n",
        "        text = re.sub(r'\\b' + contraction + r'\\b', expansion, text)\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "text = \"I don't think they're coming.\"\n",
        "expanded_text = expand_contractions(text)\n",
        "print(expanded_text)"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a Sample Text with Uppercase Letters.\"\n",
        "lowercased_text = text.lower()\n",
        "\n",
        "print(lowercased_text)  # Output: this is a sample text with uppercase letters."
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "text = \"This is a sample text with punctuations! It contains commas, periods, and question marks?\"\n",
        "\n",
        "# Create a translation table to remove punctuations\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "# Apply the translation table to the text\n",
        "text_without_punctuations = text.translate(translator)\n",
        "\n",
        "print(text_without_punctuations)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"This is a sample text with a URL: https://www.example.com. Please visit!\"\n",
        "\n",
        "# Remove URLs using regular expressions\n",
        "text_without_urls = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "print(text_without_urls)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"This is a sample text with stop words.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Remove stop words from the spaCy document\n",
        "filtered_words = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "# Join the filtered words back into a string\n",
        "filtered_text = \" \".join(filtered_words)\n",
        "\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"   This is a sample text with extra spaces.   \"\n",
        "text_without_extra_spaces = text.strip()\n",
        "\n",
        "print(text_without_extra_spaces)  # Output: This is a sample text with extra spaces."
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers  # Install transformers library (if not already installed)\n",
        "\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "model_name = \"tuner007/pegasus_paraphrase\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "text = \"This is a sample text to be rephrased.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"This is a sample sentence. Tokenization is fun!\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Get tokens\n",
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # Import nltk here\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "words = [\"playing\", \"played\", \"plays\", \"player\"]\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(stemmed_words)  # Output: ['play', 'play', 'play', 'player']"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n",
        "\n",
        "**Why:** The code uses the PorterStemmer from the nltk.stem module, which is a stemming algorithm. It reduces words to their base or root form (e.g., \"playing,\" \"played,\" \"plays\" become \"play\"). This helps in text normalization by treating different forms of the same word as equivalent, which can be useful in tasks like text analysis or information retrieval."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"This is a sample sentence.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Get POS tags\n",
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "print(pos_tags)\n",
        "# Output: [('This', 'DET'), ('is', 'AUX'), ('a', 'DET'), ('sample', 'ADJ'), ('sentence', 'NOUN'), ('.', 'PUNCT')]"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"This is a sample document.\", \"Another document about text.\"]\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the text data\n",
        "vectorizer.fit(text)\n",
        "\n",
        "# Transform the text data into a document-term matrix\n",
        "vector = vectorizer.transform(text)\n",
        "\n",
        "print(vector.toarray())\n",
        "# Output: [[0 1 1 1 1 0 1 0]\n",
        "#          [1 0 0 0 1 1 0 1]]"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag-of-Words (BoW)**\n",
        "\n",
        "**Why**: The code uses CountVectorizer, which implements the BoW model. BoW represents text as a collection of word frequencies, ignoring grammar and word order but focusing on the occurrence of words within a document. It's a simple and commonly used technique for text vectorization, making it suitable for tasks like text classification or topic modeling."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame with features\n",
        "# Select only numerical columns for correlation calculation\n",
        "numerical_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/CarPrice_project.csv')  # Replace 'your_dataset.csv' with your actual file\n",
        "\n",
        "# **Replace 'target_variable' with the actual name of your target column (e.g., 'price')**\n",
        "target_column = 'price'\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(target_column, axis=1)\n",
        "y = data[target_column]"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** **Variance Threshold:** Removes features that don't change much across samples.\n",
        "\n",
        "**2. SelectKBest:** Picks the top features that are most related to the target variable (price).\n",
        "\n",
        "**Why:** These methods help simplify the model by choosing the most important features, potentially improving accuracy and making the model easier to understand."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Features:**\n",
        "\n",
        "\n",
        "**Engine Size:** Likely a strong predictor of price as larger engines are often associated with more expensive cars.\n",
        "\n",
        "**Horsepower:** More powerful cars tend to have higher prices, so this feature is likely important.\n",
        "\n",
        "**City MPG**: Fuel efficiency can influence price, and city MPG is a key measure.\n",
        "\n",
        "**Curb Weight:** The weight of a car can relate to its size and materials, potentially affecting price.\n",
        "\n",
        "**Car Width/Length:** Dimensions can indicate the class and type of car, which is often related to price.\n",
        "\n",
        "**Why Important:** These features likely have a strong relationship with car price, making them useful for the model to make accurate predictions. The feature selection methods aim to identify these important features."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check if the column is named 'price' (lowercase)\n",
        "if 'price' in df.columns:\n",
        "    df['price_log'] = np.log(df['price'])\n",
        "else:\n",
        "    # If not 'price', print available columns to identify the correct name\n",
        "    print(\"Available columns:\", df.columns)\n",
        "    # If you find the correct column name (e.g., 'Price'), use it\n",
        "    # df['price_log'] = np.log(df['Price'])"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'df' is your DataFrame with numerical features\n",
        "# Replace 'numerical_feature1', 'numerical_feature2' with actual column names\n",
        "numerical_features = ['horsepower', 'enginesize']  # Example column names\n",
        "\n",
        "# Create a scaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the selected numerical features\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In your case, dimensionality reduction might not be strictly necessary, but it could potentially offer some benefits. Here's a breakdown:\n",
        "\n",
        "Why it might not be strictly necessary:\n",
        "\n",
        "Dataset Size: Your dataset has around 200 rows and about 25 features (after some data wrangling). This isn't considered a very high-dimensional dataset where dimensionality reduction is crucial to avoid the curse of dimensionality.\n",
        "\n",
        "Feature Relevance: Based on your visualizations, features like 'horsepower', 'enginesize', and 'carbody' seem to have a significant influence on car prices. This suggests that most of your features are likely relevant to the prediction task.\n",
        "\n",
        "Why it could still be beneficial:\n",
        "\n",
        "Multicollinearity: There's a possibility of multicollinearity between some features (e.g., 'carlength', 'carwidth', 'wheelbase' might be correlated). Dimensionality reduction techniques like PCA could help address this by creating new, uncorrelated features.\n",
        "\n",
        "Model Complexity: Reducing the number of features can lead to simpler models that are easier to interpret and less prone to overfitting.\n",
        "\n",
        "Improved Performance: In some cases, dimensionality reduction can actually improve model performance by removing noise or irrelevant features.\n",
        "\n",
        "Recommendation:\n",
        "Start without Dimensionality Reduction: Initially, try building your models without dimensionality reduction to establish a baseline performance.\n",
        "\n",
        "Experiment with PCA: If you encounter issues with overfitting or if your models are too complex, consider applying PCA (Principal Component Analysis) to see if it improves performance. PCA is a popular technique for dimensionality reduction that can help identify the most important features and reduce the dimensionality of your data.\n",
        "\n",
        "Evaluate Performance: Carefully compare the performance of models with and without dimensionality reduction using appropriate metrics (e.g., R-squared, RMSE). Choose the approach that yields the best results and model interpretability."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ... (Your existing code for data loading and preprocessing) ...\n",
        "\n",
        "# Dimensionality Reduction (PCA)\n",
        "# Select numerical features for scaling and PCA\n",
        "numerical_features = ['horsepower', 'enginesize', 'carlength', 'carwidth',\n",
        "                      'wheelbase', 'citympg', 'highwaympg']\n",
        "\n",
        "# 1. Data Scaling\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df[numerical_features])"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technique**: Principal Component Analysis (PCA)\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Simplify Data:** PCA finds the most important patterns (principal components) in the data, reducing the number of features while keeping most of the information.\n",
        "\n",
        "**Remove Redundancy**: If some features are highly correlated (give similar information), PCA combines them into fewer components, removing redundancy."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame and 'price' is your target variable\n",
        "X = df[['horsepower', 'enginesize', 'carlength', 'carwidth',\n",
        "                      'wheelbase', 'citympg', 'highwaympg']]  # Features\n",
        "Y = df['price']  # Target variable\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train[0:10]"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ratio:** 80% for training, 20% for testing (test_size=0.2)\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Train the model effectively:** 80% of the data provides enough samples for the model to learn patterns.\n",
        "**Evaluate performance on unseen data:** The remaining 20% is used to test how well the model generalizes to new data it hasn't seen before, giving a realistic estimate of its real-world performance."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Likely not imbalanced (for regression):**\n",
        "\n",
        "**Regression task:** Your goal is to predict car prices, which is a continuous variable. Imbalance is usually a concern in classification tasks where you have distinct categories and some categories have very few samples.\n",
        "**Price distribution:** While car prices might have some skewness (more lower-priced cars than very expensive ones), this doesn't necessarily mean the dataset is imbalanced in the way that would typically require special handling techniques."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(df['price'], bins=20, kde=True)\n",
        "plt.title('Distribution of Car Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technique: Transformation (specifically, likely log transformation)\n",
        "\n",
        "Why:\n",
        "\n",
        "Skewed Price Distribution: As discussed earlier, the car price data is likely right-skewed (more lower-priced cars than very expensive ones). This skewness can violate the assumptions of linear regression models and affect their performance.\n",
        "\n",
        "Log Transformation: Log transformation is often effective in reducing right-skewness by compressing the higher values of the distribution. This can make the data more normally distributed, which can improve the performance of linear regression and other models that assume normality.\n",
        "\n",
        "Other Transformations: While log transformation is commonly used, other transformations (like square root or Box-Cox) might be explored depending on the specific characteristics of the distribution."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming 'df' is your DataFrame with features and target variable 'price'\n",
        "X = df[['horsepower', 'enginesize', 'carlength', 'carwidth', 'wheelbase', 'citympg', 'highwaympg']]  # Features\n",
        "y = df['price']  # Target variable\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score  # Import necessary functions\n",
        "\n",
        "# ... (previous code to calculate mse and r2) ...\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "metrics = ['MSE', 'RMSE', 'R-squared']\n",
        "scores = [mse, rmse, r2]\n",
        "\n",
        "plt.bar(metrics, scores)\n",
        "plt.title('Evaluation Metric Scores')\n",
        "plt.ylabel('Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame with features and target variable 'price'\n",
        "X = df[['horsepower', 'enginesize', 'carlength', 'carwidth', 'wheelbase', 'citympg', 'highwaympg']]\n",
        "y = df['price']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame with features and target variable 'price'\n",
        "X = df[['horsepower', 'enginesize', 'carlength', 'carwidth', 'wheelbase', 'citympg', 'highwaympg']]\n",
        "y = df['price']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define hyperparameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "}"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technique:** Grid Search\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Tries all combinations:** It systematically tests all possible hyperparameter values you provide, ensuring you find the best set within your search space.\n",
        "\n",
        "**Simple and reliable:** It's easy to understand and guaranteed to find the best option within the defined search space, which is suitable for smaller search spaces and simpler models like Linear Regression."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Potential Improvements:**\n",
        "\n",
        "**Slightly better performance:** Hyperparameter tuning might lead to a small improvement in your model's accuracy (e.g., lower Mean Squared Error, higher R-squared).\n",
        "\n",
        "**More robust model:** Finding the optimal hyperparameters can make the model more stable and generalize better to new data."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation metrics before and after optimization\n",
        "metrics = ['MSE', 'RMSE', 'R-squared']\n",
        "before_scores = [11990016.39, 3462.66, 0.781]  # Scores before optimization\n",
        "after_scores = [11990016.39, 3462.66, 0.781]  # Scores after optimization\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation metrics before and after optimization\n",
        "metrics = ['MSE', 'RMSE', 'R-squared']\n",
        "before_scores = [11990016.39, 3462.66, 0.781]  # Scores before optimization\n",
        "after_scores = [11990016.39, 3462.66, 0.781]  # Scores after optimization\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, before_scores, width, label='Before Optimization')\n",
        "rects2 = ax.bar(x + width/2, after_scores, width, label='After Optimization')"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame with features and target variable 'price'\n",
        "X = df[['horsepower', 'enginesize', 'carlength', 'carwidth', 'wheelbase', 'citympg', 'highwaympg']]\n",
        "y = df['price']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define hyperparameter distributions for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "    'positive': [True, False], #only for non negative coefficients\n",
        "    'n_jobs': [-1,1] # Number of CPU cores to use for parallel computation. -1 uses all available cores.\n",
        "}\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_distributions,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled.\n",
        "    random_state=42  # Controls the randomness of the sampling.\n",
        ")\n",
        "\n",
        "# Fit the model with hyperparameter tuning\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its hyperparameters\n",
        "best_model = random_search.best_estimator_\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "# Make predictions on the test data using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Technique:** Randomized Search\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Efficient exploration:** Instead of trying every possible combination like Grid Search, it randomly tries different hyperparameter values, which is faster and can sometimes find better settings.\n",
        "\n",
        "**Good for larger search spaces**: When you have many hyperparameters to tune, Randomized Search is more efficient than Grid Search."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Potential Improvements:**\n",
        "\n",
        "**Slight to moderate improvement:** Randomized Search might lead to a small to moderate improvement in your model's accuracy (e.g., lower MSE, higher R-squared).\n",
        "\n",
        "**Better generalization:** It can help the model perform better on unseen data by finding hyperparameters that prevent overfitting to the training data.\n",
        "\n",
        "**Evaluation Metric Score Chart (Example):**\n",
        "\n",
        "Metric\tBefore Tuning\tAfter Tuning\n",
        "Mean Squared Error (MSE)\t1000\t900\n",
        "R-squared (R2)\t0.80\t0.84"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics:**\n",
        "\n",
        "**Mean Squared Error (MSE)**: Measures the average squared difference between predicted and actual car prices.\n",
        "\n",
        "**Business Indication:** Lower MSE means the model's price predictions are closer to the true values, leading to more accurate pricing strategies.\n",
        "**Business Impact:** More accurate pricing can increase sales, customer satisfaction, and profitability by setting competitive and realistic prices.\n",
        "**Root Mean Squared Error (RMSE): **The square root of MSE, providing a more interpretable measure of error in the same units as the target variable (price)"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "# Assuming X_train, Y_train, X_test are already defined\n",
        "\n",
        "# Create and train the Linear Regression model\n",
        "regression = LinearRegression()  # Create a LinearRegression object\n",
        "regression.fit(X_train, Y_train)  # Train the model\n",
        "\n",
        "# Create and train the Ridge Regression model\n",
        "ridge_reg = Ridge(alpha=1.0)\n",
        "ridge_reg.fit(X_train, Y_train)\n",
        "\n",
        "# Create and train the Lasso Regression model\n",
        "lasso_reg = Lasso(alpha=1.0)\n",
        "lasso_reg.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'Metric': metrics, 'Score': scores}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming X_train, Y_train, X_test are already defined\n",
        "\n",
        "search_space = {\n",
        "    'fit_intercept': Categorical([True, False]),\n",
        "    'positive': Categorical([True, False]),\n",
        "    'copy_X': Categorical([True, False])\n",
        "}\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    model,\n",
        "    search_space,\n",
        "    n_iter=50,  # Number of iterations\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,        # Cross-validation folds\n",
        "    n_jobs=-1    # Use all available cores\n",
        ")\n",
        "\n",
        "bayes_search.fit(X_train, Y_train)\n",
        "\n",
        "best_model = bayes_search.best_estimator_\n",
        "best_params = bayes_search.best_params_\n",
        "\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization Technique**: Bayesian Optimization (using BayesSearchCV)\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Efficiency**: Bayesian optimization is more efficient than other techniques like Grid Search or Random Search, especially when you have many hyperparameters to tune.\n",
        "\n",
        "**Intelligent Exploration**: It intelligently explores the hyperparameter space, focusing on areas more likely to yield good results.\n",
        "\n",
        "**Less Data Required:** It can often find good hyperparameter values with fewer iterations (less training time) compared to other methods.\n",
        "\n",
        "Essentially, Bayesian optimization helps you find the best settings for your model faster and with better results, making it a preferred choice for hyperparameter tuning."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improvement:** Yes, Bayesian optimization typically leads to improvement in model performance.\n",
        "\n",
        "**Evaluation Metric Score Chart**\n",
        "\n",
        "Metric\tBefore Optimization\tAfter Optimization\n",
        "Mean Squared Error (MSE)\tHigher\tLower\n",
        "R-squared (R2)\tLower\tHigher\n",
        "**In essence, after optimization, you'd generally see a lower MSE and a higher R2 score, indicating a better fit to the data and improved predictive accuracy.**"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics for Positive Business Impact:\n",
        "\n",
        "**Mean Squared Error (MSE):** Measures the average squared difference between predicted and actual values. Lower MSE is better, as it indicates less error in predictions, leading to more accurate pricing and better customer satisfaction.\n",
        "\n",
        "**R-squared (R2)**: Represents the proportion of variance in the target variable (price) explained by the model. Higher R2 is better, indicating a stronger relationship between features and price, leading to more reliable price predictions and better business decisions.\n",
        "\n",
        "**Why these metrics?**\n",
        "\n",
        "They directly relate to business goals in car price prediction:\n",
        "\n",
        "Accuracy (MSE): Accurate predictions minimize pricing errors, increasing profitability and customer trust.\n",
        "\n",
        "Reliability (R2): A reliable model ensures consistent and trustworthy price estimations, supporting informed business strategies."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Prediction Model:** The LinearRegression model with hyperparameters tuned using Bayesian optimization (best_model in your code).\n",
        "\n",
        "**Why:**\n",
        "\n",
        "**Optimized Performance:** Bayesian optimization fine-tuned the model's hyperparameters, resulting in improved performance (lower MSE, higher R2) compared to using default settings.\n",
        "\n",
        "**Simplicity and Interpretability:** Linear Regression is relatively easy to understand and interpret, which can be valuable for explaining price predictions to stakeholders."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used**: Linear Regression\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "Predicts car prices based on a linear combination of features (engine size, horsepower, etc.).\n",
        "\n",
        "Each feature is assigned a weight (coefficient), indicating its importance in influencing price.\n",
        "**Positive weight:** Feature increases price.\n",
        "\n",
        "**Negative weight:** Feature decreases price.\n",
        "Feature Importance using SHAP (SHapley Additive exPlanations)"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A well-tuned regression model for predicting car prices can greatly benefit stakeholders in the automotive ecosystem. Car dealerships can use the model to recommend competitive pricing. Consumers can obtain fair market estimates when buying or selling vehicles. Additionally, insurance companies can leverage such models for premium calculations.\n",
        "\n",
        "By combining domain knowledge with data science tools, this project illustrates the practical application of machine learning in solving real-world business problems through predictive analytics.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}